{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HIS residue (4) has the wrong set of atoms'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output from prepare_pdbbind\n",
    "failed_pdbs = {'1h6e': 'HIS residue (35) has the wrong set of atoms', '1svh': 'HIS residue (78) has the wrong set of atoms', '3bho': 'HIS residue (19) has the wrong set of atoms', '3bc5': 'HIS residue (6) has the wrong set of atoms', '3fxv': 'HIS residue (36) has the wrong set of atoms', '3s74': 'HIS residue (0) has the wrong set of atoms', '3smq': 'HIS residue (39) has the wrong set of atoms', '2y4k': 'HIS residue (50) has the wrong set of atoms', '3sm0': 'HIS residue (9) has the wrong set of atoms', '4hai': 'HIS residue (43) has the wrong set of atoms', '4ehm': 'HIS residue (1) has the wrong set of atoms', '4ayt': 'HIS residue (36) has the wrong set of atoms', '3rv9': 'HIS residue (21) has the wrong set of atoms', '3uib': 'HIS residue (50) has the wrong set of atoms', '4ayw': 'HIS residue (31) has the wrong set of atoms', '4gv8': 'HIS residue (34) has the wrong set of atoms', '4bae': 'HIS residue (34) has the wrong set of atoms', '4mb9': 'HIS residue (38) has the wrong set of atoms', '4ezj': 'HIS residue (18) has the wrong set of atoms', '4j8t': 'HIS residue (31) has the wrong set of atoms', '4aw8': 'HIS residue (40) has the wrong set of atoms', '4kv9': 'HIS residue (45) has the wrong set of atoms', '4kva': 'HIS residue (47) has the wrong set of atoms', '4q2k': 'HIS residue (8) has the wrong set of atoms', '4ryl': 'HIS residue (35) has the wrong set of atoms', '4rrr': 'HIS residue (48) has the wrong set of atoms', '4rrq': 'HIS residue (23) has the wrong set of atoms', '4yxu': 'HIS residue (1) has the wrong set of atoms', '4zyv': 'HIS residue (3) has the wrong set of atoms', '5iui': 'HIS residue (4) has the wrong set of atoms', '5izu': 'HIS residue (2) has the wrong set of atoms', '4xuh': 'HIS residue (12) has the wrong set of atoms', '4yb6': 'HIS residue (43) has the wrong set of atoms', '5hx8': 'HIS residue (6) has the wrong set of atoms', '5gic': 'HIS residue (48) has the wrong set of atoms', '5j3s': 'HIS residue (4) has the wrong set of atoms', '5mrd': 'HIS residue (5) has the wrong set of atoms', '5q0x': 'HIS residue (36) has the wrong set of atoms', '5ngf': 'HIS residue (41) has the wrong set of atoms', '5ien': 'HIS residue (63) has the wrong set of atoms', '5one': 'HIS residue (49) has the wrong set of atoms', '5if6': 'HIS residue (36) has the wrong set of atoms', '5wqd': 'HIS residue (21) has the wrong set of atoms', '6gbx': 'HIS residue (13) has the wrong set of atoms', '5wkl': 'HIS residue (45) has the wrong set of atoms', '6do4': 'HIS residue (54) has the wrong set of atoms', '5ypw': 'HIS residue (4) has the wrong set of atoms', '6ck3': 'HIS residue (6) has the wrong set of atoms', '5wgq': 'HIS residue (14) has the wrong set of atoms', '6do5': 'HIS residue (55) has the wrong set of atoms', '6hjk': 'HIS residue (25) has the wrong set of atoms', '6ck6': 'HIS residue (7) has the wrong set of atoms', '6cmr': 'HIS residue (10) has the wrong set of atoms', '6cjy': 'HIS residue (7) has the wrong set of atoms', '6c5t': 'HIS residue (11) has the wrong set of atoms', '6qyo': 'HIS residue (19) has the wrong set of atoms', '6i4x': 'HIS residue (42) has the wrong set of atoms', '6edl': 'HIS residue (3) has the wrong set of atoms', '6r0x': 'HIS residue (61) has the wrong set of atoms', '6e0r': 'HIS residue (4) has the wrong set of atoms', '6ebw': 'HIS residue (4) has the wrong set of atoms'}\n",
    "failed_pdb_list = list(failed_pdbs.keys())\n",
    "print(len(failed_pdbs))\n",
    "failed_pdbs['5ypw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3nzc fails because plip does not find an interaction partner - this is also true in the web service!\n",
    "# therefore I exclude it\n",
    "failed_pdb_list.append('3nzc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1h6e', '1svh', '3bho', '3bc5', '3fxv', '3s74', '3smq', '2y4k', '3sm0', '4hai', '4ehm', '4ayt', '3rv9', '3uib', '4ayw', '4gv8', '4bae', '4mb9', '4ezj', '4j8t', '4aw8', '4kv9', '4kva', '4q2k', '4ryl', '4rrr', '4rrq', '4yxu', '4zyv', '5iui', '5izu', '4xuh', '4yb6', '5hx8', '5gic', '5j3s', '5mrd', '5q0x', '5ngf', '5ien', '5one', '5if6', '5wqd', '6gbx', '5wkl', '6do4', '5ypw', '6ck3', '5wgq', '6do5', '6hjk', '6ck6', '6cmr', '6cjy', '6c5t', '6qyo', '6i4x', '6edl', '6r0x', '6e0r', '6ebw', '3nzc']\n"
     ]
    }
   ],
   "source": [
    "print(failed_pdb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@  pistacking\n",
      "Model weights: 47\n",
      "Training size: 4 Test size: 4\n",
      "Using cuda device.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/iwe20/Projects/LearnableInteractionKernel/data.py\", line 25, in __getitem__\n    rec_graph = torch.load(path + \"_rec.graph\")\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 998, in load\n    with _open_file_like(f, 'rb') as opened_file:\n         ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 445, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 426, in __init__\n    super().__init__(open(name, mode))\n                     ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'pdbbind2020/2gst/2gst_rec.graph'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m\n\u001b[1;32m     52\u001b[0m dataloader_test \u001b[38;5;241m=\u001b[39m DataLoader(dataset_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mdataset_test\u001b[38;5;241m.\u001b[39mcollate_fn, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset_train), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset_test))\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minter_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/LearnableInteractionKernel/train.py:122\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, eval_every_n_epochs, dataloader_train, dataloader_eval, interaction_model, loss_fn, optimizer, save_weights)\u001b[0m\n\u001b[1;32m    120\u001b[0m best_eval_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m99999999.9\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     epoch_loss, confusion_matrix \u001b[38;5;241m=\u001b[39m \u001b[43minteraction_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteraction_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     tp \u001b[38;5;241m=\u001b[39m confusion_matrix[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    124\u001b[0m     fn \u001b[38;5;241m=\u001b[39m confusion_matrix[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/LearnableInteractionKernel/train.py:61\u001b[0m, in \u001b[0;36minteraction_epoch\u001b[0;34m(dataloader, interaction_model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     60\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros( (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint )\n\u001b[0;32m---> 61\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrec_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlig_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteraction_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlig_graphs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrec_g\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrec_graphs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/home/iwe20/Projects/LearnableInteractionKernel/data.py\", line 25, in __getitem__\n    rec_graph = torch.load(path + \"_rec.graph\")\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 998, in load\n    with _open_file_like(f, 'rb') as opened_file:\n         ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 445, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/iwe20/anaconda3/envs/torch/lib/python3.11/site-packages/torch/serialization.py\", line 426, in __init__\n    super().__init__(open(name, mode))\n                     ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'pdbbind2020/2gst/2gst_rec.graph'\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import torch\n",
    "from torch import nn\n",
    "from data import PDBBindInteractionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from e3nn import o3\n",
    "from model import InteractionPredictor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "lp_pdbbind = pd.read_csv('LP_PDBBind.csv', index_col=0)# TODO: Fix the 61 failed pdbs and remove this exclusion filter\n",
    "train_pdbs = [ x for x in list(lp_pdbbind[(lp_pdbbind['new_split'] == 'train') & lp_pdbbind.CL1 & ~lp_pdbbind.covalent].index) if x not in failed_pdb_list ]\n",
    "test_pdbs = [ x for x in list(lp_pdbbind[(lp_pdbbind['new_split'] == 'test') & lp_pdbbind.CL1 & ~lp_pdbbind.covalent].index) if x not in failed_pdb_list ]\n",
    "\n",
    "train_pdbs = ['2gst', '5fnu', '6gl8', '1a0q']\n",
    "test_pdbs = train_pdbs\n",
    "\n",
    "['hbond', 'pistacking', 'hydrophobic', 'pication', 'saltbridges', 'halogenbond']\n",
    "for interaction_type in ['pistacking', 'hydrophobic', 'pication', 'saltbridges', 'halogenbond']:\n",
    "    print(\"@@@@ \", interaction_type)\n",
    "    inter_pred = InteractionPredictor(n_pattern_layers = 1, \n",
    "                                  radius = 15.0,\n",
    "                                  irreps_input = o3.Irreps(\"1x0e\"),\n",
    "                                  irreps_message = o3.Irreps(\"1x0e\"),\n",
    "                                  pattern_spherical_harmonics_l = 1,\n",
    "                                  irreps_node = o3.Irreps(\"1x0e\"),\n",
    "                                  node_embedding_size = 1, \n",
    "                                  node_emb_hidden_layers = [], \n",
    "                                  node_act = torch.relu,\n",
    "                                  edge_embedding_size = 1,\n",
    "                                  edge_emb_hidden_layers = [],\n",
    "                                  edge_act = torch.relu,\n",
    "                                  msg_weights_hidden_layers = [],\n",
    "                                  msg_weights_act = torch.relu,\n",
    "                                  node_update_hidden_layers = [], \n",
    "                                  node_update_act = torch.relu,\n",
    "                                  basis_density_per_A = 1, \n",
    "                                  inter_spherical_harmonics_l = 1,\n",
    "                                  inter_tp_weights_hidden_layers = [], \n",
    "                                  inter_tp_weights_act = torch.relu,\n",
    "                                  irreps_out = o3.Irreps(\"1x0e\"))\n",
    "    print(\"Model weights:\", sum(p.numel() for p in inter_pred.parameters() if p.requires_grad))\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(inter_pred.parameters(), lr=1e-3, amsgrad=True)\n",
    "\n",
    "    dataset_train = PDBBindInteractionDataset(\"pdbbind2020/\", train_pdbs, interaction_type)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=False, collate_fn=dataset_train.collate_fn, pin_memory=True, num_workers=1)\n",
    "    dataset_test = PDBBindInteractionDataset(\"pdbbind2020/\", test_pdbs, interaction_type)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=dataset_test.collate_fn, pin_memory=True, num_workers=1)\n",
    "\n",
    "    print(\"Training size:\", len(dataset_train), \"Test size:\", len(dataset_test))\n",
    "\n",
    "    train.train(1, 1, dataloader_train, dataloader_test, inter_pred, loss_fn, optimizer, save_weights=False)\n",
    "    print(\"\\n-------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pistack(proteinring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca37290>, <openbabel.pybel.Atom object at 0x7fdd7ca37310>, <openbabel.pybel.Atom object at 0x7fdd7ca37390>, <openbabel.pybel.Atom object at 0x7fdd7ca37410>, <openbabel.pybel.Atom object at 0x7fdd7ca37490>, <openbabel.pybel.Atom object at 0x7fdd7ca37510>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca8bb90>, <openbabel.pybel.Atom object at 0x7fdd7ca8bf10>, <openbabel.pybel.Atom object at 0x7fdd7ca8bed0>, <openbabel.pybel.Atom object at 0x7fdd7ca8b190>, <openbabel.pybel.Atom object at 0x7fdd7ca90450>, <openbabel.pybel.Atom object at 0x7fdd7ca90350>], atoms_orig_idx=[1523, 1524, 1525, 1526, 1527, 1528], normal=array([ 0.56246768, -0.48762181, -0.6677238 ]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca8e790> >, center=[14.730833333333331, 60.31583333333334, 22.852999999999998], type='6-membered'), ligandring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca81b50>, <openbabel.pybel.Atom object at 0x7fdd7ca81bd0>, <openbabel.pybel.Atom object at 0x7fdd7ca81c50>, <openbabel.pybel.Atom object at 0x7fdd7ca81c90>, <openbabel.pybel.Atom object at 0x7fdd7ca81d90>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca82e10>, <openbabel.pybel.Atom object at 0x7fdd7ca82e90>, <openbabel.pybel.Atom object at 0x7fdd7ca82f10>, <openbabel.pybel.Atom object at 0x7fdd7ca82f90>, <openbabel.pybel.Atom object at 0x7fdd7ca83010>], atoms_orig_idx=[2222, 2223, 2224, 2225, 2227], normal=array([-0.47093353,  0.50041329,  0.72650406]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca7fa80> >, center=[12.861799999999999, 61.367399999999996, 25.6392], type='5-membered'), distance=3.5159619587753705, angle=6.278858012008982, offset=0.7700735041456126, type='P', restype='TYR', resnr=200, reschain='A', restype_l='L6I', resnr_l=1, reschain_l='A')\n",
      "pistack(proteinring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca37290>, <openbabel.pybel.Atom object at 0x7fdd7ca37310>, <openbabel.pybel.Atom object at 0x7fdd7ca37390>, <openbabel.pybel.Atom object at 0x7fdd7ca37410>, <openbabel.pybel.Atom object at 0x7fdd7ca37490>, <openbabel.pybel.Atom object at 0x7fdd7ca37510>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca8bb90>, <openbabel.pybel.Atom object at 0x7fdd7ca8bf10>, <openbabel.pybel.Atom object at 0x7fdd7ca8bed0>, <openbabel.pybel.Atom object at 0x7fdd7ca8b190>, <openbabel.pybel.Atom object at 0x7fdd7ca90450>, <openbabel.pybel.Atom object at 0x7fdd7ca90350>], atoms_orig_idx=[1523, 1524, 1525, 1526, 1527, 1528], normal=array([ 0.56246768, -0.48762181, -0.6677238 ]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca8e790> >, center=[14.730833333333331, 60.31583333333334, 22.852999999999998], type='6-membered'), ligandring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7cb01410>, <openbabel.pybel.Atom object at 0x7fdd7cb02d10>, <openbabel.pybel.Atom object at 0x7fdd7c9ed6d0>, <openbabel.pybel.Atom object at 0x7fdd7ca81ad0>, <openbabel.pybel.Atom object at 0x7fdd7ca81b50>, <openbabel.pybel.Atom object at 0x7fdd7ca81d90>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca83290>, <openbabel.pybel.Atom object at 0x7fdd7ca832d0>, <openbabel.pybel.Atom object at 0x7fdd7ca83390>, <openbabel.pybel.Atom object at 0x7fdd7ca83410>, <openbabel.pybel.Atom object at 0x7fdd7ca83490>, <openbabel.pybel.Atom object at 0x7fdd7ca83550>], atoms_orig_idx=[2218, 2219, 2220, 2221, 2222, 2227], normal=array([-0.47088643,  0.50087519,  0.72621623]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca7ff00> >, center=[14.423833333333334, 62.8605, 25.622500000000002], type='6-membered'), distance=3.773553722215235, angle=6.275425765167569, offset=1.5723268846533804, type='P', restype='TYR', resnr=200, reschain='A', restype_l='L6I', resnr_l=1, reschain_l='A')\n",
      "pistack(proteinring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7cb08b10>, <openbabel.pybel.Atom object at 0x7fdd7cb08a90>, <openbabel.pybel.Atom object at 0x7fdd7cb08a10>, <openbabel.pybel.Atom object at 0x7fdd7cb08990>, <openbabel.pybel.Atom object at 0x7fdd7cb08910>, <openbabel.pybel.Atom object at 0x7fdd7cb08890>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca91850>, <openbabel.pybel.Atom object at 0x7fdd7ca91990>, <openbabel.pybel.Atom object at 0x7fdd7ca919d0>, <openbabel.pybel.Atom object at 0x7fdd7ca91a50>, <openbabel.pybel.Atom object at 0x7fdd7ca91ad0>, <openbabel.pybel.Atom object at 0x7fdd7ca91bd0>], atoms_orig_idx=[65, 66, 67, 68, 69, 70], normal=array([-0.71583769, -0.11646997,  0.68848468]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca8e310> >, center=[7.745666666666668, 67.59916666666668, 33.28216666666666], type='6-membered'), ligandring=aromatic_ring(atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca82690>, <openbabel.pybel.Atom object at 0x7fdd7ca82710>, <openbabel.pybel.Atom object at 0x7fdd7ca82790>, <openbabel.pybel.Atom object at 0x7fdd7ca82810>, <openbabel.pybel.Atom object at 0x7fdd7ca82890>, <openbabel.pybel.Atom object at 0x7fdd7ca82910>], orig_atoms=[<openbabel.pybel.Atom object at 0x7fdd7ca83c90>, <openbabel.pybel.Atom object at 0x7fdd7ca83cd0>, <openbabel.pybel.Atom object at 0x7fdd7ca83d90>, <openbabel.pybel.Atom object at 0x7fdd7ca83e10>, <openbabel.pybel.Atom object at 0x7fdd7ca83e90>, <openbabel.pybel.Atom object at 0x7fdd7ca83f50>], atoms_orig_idx=[2245, 2246, 2247, 2248, 2249, 2250], normal=array([-0.64377836, -0.20248445,  0.73793595]), obj=<openbabel.openbabel.OBRing; proxy of <Swig Object of type 'OpenBabel::OBRing *' at 0x7fdd7ca7fc60> >, center=[10.537333333333333, 67.2905, 31.0265], type='6-membered'), distance=3.602320085722531, angle=7.030204767850739, offset=0.7864603718549119, type='P', restype='TYR', resnr=9, reschain='A', restype_l='L6I', resnr_l=1, reschain_l='A')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  64, 2244],\n",
       "        [  64, 2245],\n",
       "        [  64, 2246],\n",
       "        [  64, 2247],\n",
       "        [  64, 2248],\n",
       "        [  64, 2249],\n",
       "        [  65, 2244],\n",
       "        [  65, 2245],\n",
       "        [  65, 2246],\n",
       "        [  65, 2247],\n",
       "        [  65, 2248],\n",
       "        [  65, 2249],\n",
       "        [  66, 2244],\n",
       "        [  66, 2245],\n",
       "        [  66, 2246],\n",
       "        [  66, 2247],\n",
       "        [  66, 2248],\n",
       "        [  66, 2249],\n",
       "        [  67, 2244],\n",
       "        [  67, 2245],\n",
       "        [  67, 2246],\n",
       "        [  67, 2247],\n",
       "        [  67, 2248],\n",
       "        [  67, 2249],\n",
       "        [  68, 2244],\n",
       "        [  68, 2245],\n",
       "        [  68, 2246],\n",
       "        [  68, 2247],\n",
       "        [  68, 2248],\n",
       "        [  68, 2249],\n",
       "        [  69, 2244],\n",
       "        [  69, 2245],\n",
       "        [  69, 2246],\n",
       "        [  69, 2247],\n",
       "        [  69, 2248],\n",
       "        [  69, 2249],\n",
       "        [1522, 2217],\n",
       "        [1522, 2218],\n",
       "        [1522, 2219],\n",
       "        [1522, 2220],\n",
       "        [1522, 2221],\n",
       "        [1522, 2222],\n",
       "        [1522, 2223],\n",
       "        [1522, 2224],\n",
       "        [1522, 2226],\n",
       "        [1523, 2217],\n",
       "        [1523, 2218],\n",
       "        [1523, 2219],\n",
       "        [1523, 2220],\n",
       "        [1523, 2221],\n",
       "        [1523, 2222],\n",
       "        [1523, 2223],\n",
       "        [1523, 2224],\n",
       "        [1523, 2226],\n",
       "        [1524, 2217],\n",
       "        [1524, 2218],\n",
       "        [1524, 2219],\n",
       "        [1524, 2220],\n",
       "        [1524, 2221],\n",
       "        [1524, 2222],\n",
       "        [1524, 2223],\n",
       "        [1524, 2224],\n",
       "        [1524, 2226],\n",
       "        [1525, 2217],\n",
       "        [1525, 2218],\n",
       "        [1525, 2219],\n",
       "        [1525, 2220],\n",
       "        [1525, 2221],\n",
       "        [1525, 2222],\n",
       "        [1525, 2223],\n",
       "        [1525, 2224],\n",
       "        [1525, 2226],\n",
       "        [1526, 2217],\n",
       "        [1526, 2218],\n",
       "        [1526, 2219],\n",
       "        [1526, 2220],\n",
       "        [1526, 2221],\n",
       "        [1526, 2222],\n",
       "        [1526, 2223],\n",
       "        [1526, 2224],\n",
       "        [1526, 2226],\n",
       "        [1527, 2217],\n",
       "        [1527, 2218],\n",
       "        [1527, 2219],\n",
       "        [1527, 2220],\n",
       "        [1527, 2221],\n",
       "        [1527, 2222],\n",
       "        [1527, 2223],\n",
       "        [1527, 2224],\n",
       "        [1527, 2226]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import data\n",
    "pdb_list = ['5fnu']\n",
    "data.load_pdbbind_interactions(pdb_list[0], 'pistacking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
